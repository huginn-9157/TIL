# 分散処理

前提として、分散処理を使うということは一台のPCに入りきらないデータを扱うこと

ローカルに置くデータマートやデータウェアハウスは構造化されているデータ（＝テーブル、及びそのままSQLにインポートできるようなCSV）だが、ビッグデータで扱う領域、データレイクではそれ以外も扱う

`非構造化データ`
- テキストデータ
- 画像等

`スキーマレス（半構造化データ）`
- CSV
- JSON
- XMLなど

## Apache Hadoop 関連のコンポーネント

- MapReduce
  - 分散データ処理エンジン
- Spark
  - 分散データ処理エンジン
  - インメモリで高速化
- Hive
  - クエリエンジン
    - SQL文をMapReduceに変換する
    - バッチ処理向け
- Presto, Impala
  - 対話型クエリエンジン
    - アドホック分析向け
- YARN (Yet Another Resource Negotiator)
  - リソースマネージャー
    - 各マシンのCPUやメモリをコンテナ単位で管理する
- HDFS (Hadoop Distributed File System)
  - 分散ファイルシステム

## Hive

データマート作成の前に、非構造化データが多ければ構造化させておく必要がある（DWH）。

Hiveは、非構造化データをSQL文で構造化（列指向ストレージ：ORC形式に変換）する。

データマート作成（データの非正規化）の際は、
- Hiveでバッチ処理
- Prestoで対話式処理
と用途によって使い分ける

### データの非正規化の際の注意点

- サブクエリ内でレコードを削減する
  - 普通のRDBMSの感覚で `SELECT id, name` 等とすると、  
    期間を指定して集計するような際に大量の無駄なデータが生まれてしまう。  
    これを避ける為に、`WHERE`句で指定する際は`FROM (SELECT * table WHERE ~) `としてサブクエリ内で行う

## Presto

>クエリ実行の遅延を小さくすることを目的とされた、「対話型クエリエンジン」

>Prestoがその性能を最大限に発揮するには、  
元となるストレージが列指向のデータ構造になっている必要がある

- Java製
- 他、RDBMSやNoSQLを結合したり集計したいときにも
- Hiveとは異なり、全ての処理を並列化されたメモリ上で行う

## Spark

MapReduceに代わる分散データ処理エンジン

特徴として
- インメモリ
- pandasと同じようにデータをデータフレームとして操作できる
- Python, Scala, Javaと三つの言語でプログラミングできる
- データフレームに対してSQLで処理もかけれる

## 商用MPPとHive, Presto

用途の違いについて

- 商用MPP（Redshift等）
  - 構造化データをSQLで集計するのに最適
  - BI ✖ データウェアハウス製品は今でも鉄板
  - 運用・保守に必要な技術が少ないのが強い
- Hive
  - 何千台での利用を前提とした障害耐性
  - データ量に左右されない安定感
- Presto
  - ETLやデータの構造化には向いていないが、既存のDBを集計するのに強い（RDB、NoSQL）
  - 大量のデータにちょっとしたクエリを投げるのに最適
- Spark
  - 分散システムを使ったプログラミング環境
  - HiveとPresto、それぞれに適した操作を一回のデータ処理として行える
  - データ処理をプログラミングと考えるならば、実行環境には最適
  - 要メモリ管理